{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arguments/Parameters\n",
    "\n",
    "working_dir = '/home/jupyter/notebooks/Ancestry' #home directory for this workspace\n",
    "workspace_bucket = Sys.getenv('WORKSPACE_BUCKET') #the workspace bucket that we will upload the output to\n",
    "num.threads = 64 #Specify the number of CPUs you want to use. Some steps take a lot of compute.\n",
    "imputation.server.password = '6\\\\{VDgXClmd\\\\$iB6' #Password to download the imputed data\n",
    "phased.data.password = '16HUsumDrRBWvu' #password to download the phased (but not imputed) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.5     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.4     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.7\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.3     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.0.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load packages\n",
    "library(tidyverse)\n",
    "\n",
    "#Define functions\n",
    "show_msg <- function(x){ \n",
    "    print(x)\n",
    "    flush.console()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system(glue::glue(\"\n",
    "if [ ! -d 'mkdir {working_dir}/raw_data' ] \n",
    "then\n",
    "mkdir {working_dir}/raw_data\n",
    "fi\n",
    "\n",
    "\n",
    "if [ ! -d 'mkdir {working_dir}/raw_data/new_ccle' ] \n",
    "then\n",
    "mkdir {working_dir}/raw_data/new_ccle\n",
    "fi\n",
    "\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download and install bcftools\n",
    "#Install bcftools\n",
    "step_install_bcftools <- !file.exists(glue::glue(\"{working_dir}/software/bcftools/bcftools\"))\n",
    "\n",
    "if(step_install_bcftools) {\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/software\n",
    "git clone --recurse-submodules git://github.com/samtools/htslib.git\n",
    "git clone git://github.com/samtools/bcftools.git\n",
    "cd bcftools\n",
    "autoheader && autoconf && ./configure --enable-libgsl --enable-perl-filters\n",
    "make\n",
    "export BCFTOOLS_PLUGINS=/home/jupyter-user/notebooks/Ancestry/software/bcftools/plugins\n",
    "\")) } else {print(\"bcftools is already installed\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install tabix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the VCF files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are from the CCLEv2 dataset.\n",
    "\n",
    "There are more BAM files than VCF files, so need to ask Jeremie/Javad how to get the additional VCFs.\n",
    "\n",
    "First download the sample manifest from the terra notebook, then use the gsutil links in that manifest to download the data.\n",
    "\n",
    "Some samples have both WES and WGS data, and we want to use the WGS data in these cases. So also need to do a little work in R to make a list of files that we want to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the sample manifest\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/raw_data/new_ccle\n",
    "gsutil cp gs://fc-45c0e148-0b1c-4244-9bfc-feb559bbc514/sample.tsv .\n",
    "\"))\n",
    "\n",
    "#Load the sample manifest into R\n",
    "paste(working_dir, \"/raw_data/new_ccle\", sep = \"\") %>% setwd()\n",
    "sample.manifest = read.table('sample.tsv', sep = \"\\t\", header = T)\n",
    "\n",
    "\n",
    "#Subset the dataset so that it only contains the samples that we are interested in downloading\n",
    "samples.to.download = sample.manifest %>%\n",
    "select(entity.sample_id, stripped_cell_line_name, hg38_wgs_hc_cnn_filtered_vcf, hg38_wes_hc_cnn_filtered_vcf) %>%\n",
    "rename(\"ach_id\" = entity.sample_id, \"cell_line\" = stripped_cell_line_name, \"wgs.vcf\" = hg38_wgs_hc_cnn_filtered_vcf, \"wes.vcf\" = hg38_wes_hc_cnn_filtered_vcf) %>%\n",
    "na_if(\"\") %>%\n",
    "filter(!is.na(wgs.vcf) | !is.na(wes.vcf)) %>%\n",
    "mutate(link.to.use = ifelse(is.na(wgs.vcf), wes.vcf, wgs.vcf))\n",
    "\n",
    "\n",
    "#Extract the list of files to download. Just means we need to write one fewer line of bash code to get this data.\n",
    "download.list = samples.to.download %>%\n",
    "pull(link.to.use)\n",
    "\n",
    "\n",
    "#Export the full data frame and a list of files to download\n",
    "write.table(samples.to.download, 'samples.to.download', row.names = F, col.names = T, sep = \"\\t\", quote = FALSE)\n",
    "write.table(download.list, 'download.list', row.names = F, col.names = F, sep = \"\\t\", quote = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download all of the vcf files\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/raw_data/new_ccle\n",
    "cat download.list | while read line\n",
    "do\n",
    "echo $line\n",
    "gsutil -u cclfbilling cp $line .\n",
    "done\n",
    "\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the vcf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index all of the vcf files\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/raw_data/new_ccle\n",
    "\n",
    "for vcffile in *.vcf.gz\n",
    "do\n",
    "{working_dir}/software/tabix-0.2.6/tabix -p vcf $vcffile\n",
    "done\n",
    "\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter all of the vcf files so that they only include variants in exons\n",
    "#This list was downloade from ucsc genome browser table viewer.\n",
    "#It is UCSC RefSeq refGene, coding exons only\n",
    "\n",
    "#Download a bed file with all of the human exons\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/raw_data/new_ccle\n",
    "gsutil cp {workspace_bucket}/exon_positions .\n",
    "\"))\n",
    "\n",
    "#Filter the file\n",
    "#Note to self: Filtering with -T is much faster than with -R.\n",
    "#Second note to self: Running this command with 96 CPUs has ~8 CPUs at full load. Running it with 16 only has ~2.\n",
    "#Need to learn more about multi-threading with Bcftools. I suspect that there may be more efficient ways to run things.\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/raw_data/new_ccle\n",
    "\n",
    "for vcffile in *.vcf.gz\n",
    "do\n",
    "{working_dir}/software/bcftools/bcftools view $vcffile -T exon_positions --threads {num.threads} -o exon.$vcffile -Oz;\n",
    "done\n",
    "\"))\n",
    "\n",
    "#And then index it\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/raw_data/new_ccle\n",
    "\n",
    "for vcffile in exon.CDS*\n",
    "do\n",
    "{working_dir}/software/tabix-0.2.6/tabix -p vcf $vcffile;\n",
    "done\n",
    "\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all of the vcf files into a single vcf.gz file\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/raw_data/new_ccle\n",
    "filenames=$(find | grep 'exon' | grep '.vcf.gz' | grep -v '.tbi') \n",
    "{working_dir}/software/bcftools/bcftools merge $filenames -0 --missing-to-ref -Oz --threads {num.threads} -o hg38.new.ccle.vcf.gz\n",
    "\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-name the vcf file so that the sample names are the ACH IDs\n",
    "\n",
    "#First create a bridging file to convert from the CDS ID or cell line name to the ACH ID\n",
    "ach.to.cds = samples.to.download %>%\n",
    "select(ach_id, link.to.use, cell_line) %>%\n",
    "rename(cds_id = link.to.use) %>%\n",
    "mutate(cds_id = gsub(\"..*CDS\", \"CDS\", cds_id)) %>%\n",
    "mutate(cds_id = gsub(\"_..*\", \"\", cds_id))\n",
    "\n",
    "\n",
    "#Extract the sample names from the compiled vcf file\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/raw_data/new_ccle\n",
    "find | grep 'exon' | grep '.vcf.gz' | grep -v '.tbi' > old.sample.names\n",
    "\"))\n",
    "\n",
    "paste(working_dir, \"/raw_data/new_ccle\", sep = \"\") %>% setwd()\n",
    "old.sample.names = read.table(\"old.sample.names\", sep = \"\\t\", header = F) %>%\n",
    "pull(V1) %>%\n",
    "gsub(\"..*CDS\", \"CDS\", .) %>%\n",
    "gsub(\"_..*\", \"\", .)\n",
    "\n",
    "\n",
    "#Now convert the old sample names into the ACH ID and write them\n",
    "new.sample.names = old.sample.names %>%\n",
    "plyr::mapvalues(from = ach.to.cds$cds_id, to = ach.to.cds$ach_id)\n",
    "write.table(new.sample.names, \"new.sample.names\", sep = \"\\t\", col.names = F, row.names = F, quote = F)\n",
    "\n",
    "\n",
    "#Rename the compiled vcf.gz file\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/raw_data/new_ccle\n",
    "{working_dir}/software/bcftools/bcftools reheader --samples new.sample.names -o renamed.hg38.new.ccle.vcf.gz hg38.new.ccle.vcf.gz\n",
    "\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variants at the same position are grouped together right now. So we should un-group them.\n",
    "\n",
    "For example:\n",
    "\n",
    "Current format: chr1 // pos123456789 // ref=A // alt=G/T\n",
    "\n",
    "New format: chr1 // pos123456789 // ref=A // alt=G chr1 // pos123456789 // ref=A // alt=T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the genotype calls\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/raw_data/new_ccle\n",
    "{working_dir}/software/bcftools/bcftools norm -m - renamed.hg38.new.ccle.vcf.gz -o split.hg38.new.ccle.vcf.gz\n",
    "{working_dir}/software/tabix-0.2.6/tabix -p vcf split.hg38.new.ccle.vcf.gz\n",
    "\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove SNPs with low MAF\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/raw_data/new_ccle\n",
    "{working_dir}/software/bcftools/bcftools view -i 'MAF > 0.01' --threads {num.threads} split.hg38.new.ccle.vcf.gz -Oz -o maf.split.hg38.new.ccle.vcf.gz\n",
    "{working_dir}/software/tabix-0.2.6/tabix -p vcf maf.split.hg38.new.ccle.vcf.gz\n",
    "\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre/Post-Imputation Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project we are also interested in intronic SNPs. Unfortunately, only half of our samples are WGS. To get around that problem, we filtered the original dataset so that it only includes exons. Now we can perform SNP imputation to uncover many more SNPs. The best way to do that is with the Topmed Imputation Server.\n",
    "\n",
    "Another option is to phase the data locally with Eagle2.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to split the data by chromosome so that we can input it to the Michigan Imputation Server\n",
    "chromosomes = c(seq(from = 1, to = 22, by = 1), \"X\")\n",
    "\n",
    "for(chr in chromosomes){\n",
    "    system(glue::glue(\"\n",
    "    cd {working_dir}/raw_data/new_ccle\n",
    "    {working_dir}/software/bcftools/bcftools view -r chr{chr} maf.split.hg38.new.ccle.vcf.gz -Oz -o chr{chr}.hg38.new.ccle.vcf.gz;\n",
    "\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, there is no way to interact with the Topmed Imputation Server from command line (that I know of). So we need to bring all of the data off the cloud so that we can perform the imputation.\n",
    "\n",
    "Access the imputation server at: https://imputation.biodatacatalyst.nhlbi.nih.gov/#!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#Bring the data off the cloud#\n",
    "##############################\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/raw_data/new_ccle\n",
    "gsutil cp chr* {workspace_bucket}\n",
    "\"))\n",
    "\n",
    "#################################################\n",
    "#Bring the phased/imputed data back to the cloud#\n",
    "#################################################\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/raw_data/new_ccle\n",
    "curl -sL https://imputation.biodatacatalyst.nhlbi.nih.gov/get/430843/3f3bb6adc564ab74d7915bc04fc0533b5abe70b53b2bdb6efe51f58b412b482f | bash\"))\n",
    "\n",
    "\n",
    "#Unpack all of the .zip files\n",
    "chromosomes = c(seq(from = 1, to = 22, by = 1), \"X\")\n",
    "for(chr in chromosomes){\n",
    "    system(glue::glue(\"\n",
    "    cd {working_dir}/raw_data/new_ccle\n",
    "    unzip -P {imputation.server.password} chr_{chr}.zip\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge all of the chromosomes back together and convert it to a bcf file\n",
    "#Then index the file\n",
    "system(glue::glue(\"\n",
    "cd {working_dir}/raw_data/new_ccle\n",
    "vcffiles=$(find | grep 'dose')\n",
    "{working_dir}/software/bcftools/bcftools concat $vcffiles --threads {num.threads} -Ou -o imputed.hg38.ccle.new.bcf\n",
    "{working_dir}/software/bcftools/bcftools index imputed.hg38.ccle.new.bcf --threads {num.threads} -c -f \n",
    "\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a phased (but not imputed) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFMix requires phased data, but the imputation is far too much and takes too long to compute.\n",
    "Just create a phased version of the exon data without imputation. That should be good enough for ancestry inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#Bring the phased data back to the cloud#\n",
    "#########################################\n",
    "system(glue::glue(\"\n",
    "mkdir {working_dir}/raw_data/new_ccle/phased_only\n",
    "cd {working_dir}/raw_data/new_ccle/phased_only\n",
    "curl -sL https://imputation.biodatacatalyst.nhlbi.nih.gov/get/431074/27cb2de603dcd046c7485af0c24c21eefe1e874757f8c89f461150105469e88e | bash\n",
    "\"))\n",
    "\n",
    "#Unpack all of the .zip files, then move them up one directory and index them\n",
    "chromosomes = c(seq(from = 1, to = 22, by = 1), \"X\")\n",
    "for(chr in chromosomes){\n",
    "    system(glue::glue(\"\n",
    "    cd {working_dir}/raw_data/new_ccle/phased_only\n",
    "    unzip -P {phased.data.password} chr_{chr}.zip\n",
    "    mv chr{chr}.phased.vcf.gz {working_dir}/raw_data/new_ccle/chr{chr}.phased.vcf.gz\n",
    "    {working_dir}/software/tabix-0.2.6/tabix -p vcf {working_dir}/raw_data/new_ccle/chr{chr}.phased.vcf.gz\n",
    "\"))\n",
    "}\n",
    "\n",
    "#Delete the temp dir\n",
    "system(glue::glue(\"\n",
    "rm -rf {working_dir}/raw_data/new_ccle/phased_only\n",
    "\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some blocks of the genome were unphased because the mismatch rate is too high (I still need to figure out what this actually means). In most cases this is relatively unimportant since few regions of the genome are cut. But for the Ancestry analysis it ends up being a big deal since CLSPN is in one of these regions.\n",
    "\n",
    "As such, I think it is better to use the dataset that was 'exon filtered' -> 'unphased/unimputed', rather than the fully phased/imputed dataset. At least for most analysis for this project. The phased/imputed data will still be useful for other analysis that I am doing.\n",
    "\n",
    "I need to figure out why the error rate is so high. Maybe I need to include a pre-filtering step before giving the data to the imputation server.\n",
    "\n",
    "Note: pre-filtering by low MAF significantly improves phasing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
